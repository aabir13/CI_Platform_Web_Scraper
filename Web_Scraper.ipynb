{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aabir13/CI_Platform_Web_Scraper/blob/main/Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Web Scraper**\n",
        "\n",
        "To scrape all the necessary content about Tata Steel from Money Control website!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CmRL8MziNOP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Peers\n",
        "Based on 13 criterion we extract the Top Peer competitors of Iron and Steel!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dPR_IFHu8tVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install html-table-parser-python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqHCC299BCRg",
        "outputId": "e7ad6718-9ea4-46f0-c0d2-4d35bb7fc033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting html-table-parser-python3\n",
            "  Downloading html_table_parser_python3-0.2.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: html-table-parser-python3\n",
            "Successfully installed html-table-parser-python3-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import urllib.request\n",
        "from html_table_parser.parser import HTMLTableParser\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "10D1hlKrNeF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To read the binary contents of the html body\n",
        "def url_get_contents(url):\n",
        "  req = urllib.request.Request(url=url)\n",
        "  f = urllib.request.urlopen(req)\n",
        "  return f.read()"
      ],
      "metadata": {
        "id": "nK4LXciwA1U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Net Sales as per the latest Profit & Loss Account available: df1\n",
        "def Net_Sales():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/netsales/bse/iron-steel.html').decode('utf-8')\n",
        "  # html parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into the dataframe\n",
        "  df1 = pd.DataFrame(p.tables[2])\n",
        "  df1 = df1.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df1 = df1.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  # Obtaining the csv file\n",
        "  df1.to_csv('Net_Sales_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "Uh2gjKtnB6D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Net Profit as per the latest Profit & Loss Account available: df2\n",
        "def Net_Profit():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/netprofit/bse/iron-steel.html').decode('utf-8')\n",
        "  # html parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into the dataframe\n",
        "  df2 = pd.DataFrame(p.tables[2])\n",
        "  df2 = df2.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df2 = df2.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  # Obtaining the csv file\n",
        "  df2.to_csv('Net_Profit_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "a1ah8tCwFsR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Market capitalisation: df3\n",
        "def Market_Capitalization():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/marketcap/bse/iron-steel.html').decode('utf-8')\n",
        "  # html parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into the dataframe\n",
        "  print('Iron & Steel')\n",
        "  print('Market capitalisation as per the latest Profit & Loss Account available')\n",
        "  df3 = pd.DataFrame(p.tables[1])\n",
        "  df3 = df3.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df3 = df3.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  # Obtaining the csv file\n",
        "  df3.to_csv('Market_Capitalisation_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "itfgDuhrnG6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total Assets as per the latest Balance Sheet available: df4\n",
        "def Total_Assets():\n",
        "  xhtml=url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/totassets/bse/iron-steel.html').decode('utf-8')\n",
        "  #HTML parser object\n",
        "  p=HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into a dataframe\n",
        "  df4 = pd.DataFrame(p.tables[2])\n",
        "  df4 = df4.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df4 = df4.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  #Obtaining the csv file\n",
        "  df4.to_csv('Total_Assest_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "jtyjwD6dOT3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other Income as per the latest Profit & Loss Account available: df5\n",
        "def Other_Income():\n",
        "  xhtml=url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/othinc/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p=HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df5=pd.DataFrame(p.tables[2])\n",
        "  df5=df5.replace({\"Add to Watchlist\":\"\"}, regex=True)\n",
        "  df5=df5.replace({\"Add to Portfolio\":\"\"}, regex=True)\n",
        "  # Obtaining csv\n",
        "  df5.to_csv('Other_Income_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "ivv84i-7PzHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interest as per the latest Profit & Loss Account available: df6\n",
        "def Interest():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/interest/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df6=pd.DataFrame(p.tables[2])\n",
        "  df6=df6.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df6=df6.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv \n",
        "  df6.to_csv('Interest_Iron_and_Steel.csv') "
      ],
      "metadata": {
        "id": "Wn0TN1fBSN0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tax as per the latest Profit & Loss Account available: df7\n",
        "def Tax():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/tax/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df7=pd.DataFrame(p.tables[2])\n",
        "  df7=df7.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df7=df7.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df7.to_csv('Tax_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "a7ocCpkSTtV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trailing Twelve Months EPS: df8\n",
        "def Trailing_Twelve_Months_EPS():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/eps/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df8=pd.DataFrame(p.tables[2])\n",
        "  df8=df8.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df8=df8.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df8.to_csv('EPS_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "FECHy17iUaID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sundry Debtors/Current Assets figures as per the latest Balance Sheet available: df9\n",
        "def Sundry_Debtors():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/sdrs/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df9=pd.DataFrame(p.tables[2])\n",
        "  df9=df9.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df9=df9.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df9.to_csv('Sundry Debtors_Iron_and_Steel.csv') "
      ],
      "metadata": {
        "id": "5G-zdoyWU6Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cash & Bank Balances/Total Liabilities figures as per the latest Balance Sheet available: df10\n",
        "def Cash_and_Bank_Balances():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/cashbank/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df10=pd.DataFrame(p.tables[2])\n",
        "  df10=df10.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df10=df10.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df10.to_csv('Cash_&_Bank_Balances_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "fIf_GjPNVgUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inventory/Current Assets figures as per the latest Balance Sheet available: df11\n",
        "def Current_Assets():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/inventory/bse/iron-steel.html').decode('utf-8')\n",
        "  #HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df11=pd.DataFrame(p.tables[2])\n",
        "  df11=df11.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df11=df11.replace({\"Add to Portfolio\":\"\"}, regex = True) \n",
        "  # Obtaining csv\n",
        "  df11.to_csv('Inventory_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "7TBIS6BpXaGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debt/Liability figures as per the latest Balance Sheet available: df12\n",
        "def Debt():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/debt/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df12=pd.DataFrame(p.tables[2])\n",
        "  df12=df12.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df12=df12.replace({\"Add to Portfolio\":\"\"}, regex = True) \n",
        "  # Obtaining csv\n",
        "  df12.to_csv('Debt_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "uSCDR3obYAtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contingent Liabilities/Networth figures as per the latest Balance Sheet available: df13\n",
        "def Contingent_Liabilities():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/contliab/bse/iron-steel.html').decode('utf-8')\n",
        "  #HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df13=pd.DataFrame(p.tables[2])\n",
        "  df13=df13.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df13=df13.replace({\"Add to Portfolio\":\"\"}, regex = True) \n",
        "  # Obtaining csv\n",
        "  df13.to_csv('Contingent_Liabilities_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "41unwr8MYkUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Driver Function\n",
        "print('Category: IRON AND STEEL')\n",
        "print('Select the criteria in which you want to categorize the companies:')\n",
        "print('1: Net Sales')\n",
        "print('2: Net Profit')\n",
        "print('3: Market Capitalization')\n",
        "print('4: Total Assets')\n",
        "print('5: Other Income')\n",
        "print('6: Interest')\n",
        "print('7: Tax')\n",
        "print('8: EPS')\n",
        "print('9: Sundry Debtors/Current Assets')\n",
        "print('10: Cash & Bank Balances/Total Liabilities')\n",
        "print('11: Inventory/Current Assets')\n",
        "print('12: Debt/Liability')\n",
        "print('13: Contingent Liabilities/Networth')\n",
        "n = int(input('Enter your choice!'))\n",
        "if n==1:\n",
        "  Net_Sales()\n",
        "elif n==2:\n",
        "  Net_Profit()\n",
        "elif n==3:\n",
        "  Market_Capitalization()\n",
        "elif n==4:\n",
        "  Total_Assets()\n",
        "elif n==5:\n",
        "  Other_Income()\n",
        "elif n==6:\n",
        "  Interest()\n",
        "elif n==7:\n",
        "  Tax()\n",
        "elif n==8:\n",
        "  Trailing_Twelve_Months_EPS()\n",
        "elif n==9:\n",
        "  Sundry_Debtors()\n",
        "elif n==10:\n",
        "  Cash_and_Bank_Balances()\n",
        "elif n==11:\n",
        "  Current_Assets()\n",
        "elif n==12:\n",
        "  Debt()\n",
        "elif n==13:\n",
        "  Contingent_Liabilities()\n",
        "else:\n",
        "  print('Sorry! Wrong choice of category!')"
      ],
      "metadata": {
        "id": "a77squY-YwH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1828f65c-a9e9-419b-e12d-394a263dc6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category: IRON AND STEEL\n",
            "Select the criteria in which you want to categorize the companies:\n",
            "1: Net Sales\n",
            "2: Net Profit\n",
            "3: Market Capitalization\n",
            "4: Total Assets\n",
            "5: Other Income\n",
            "6: Interest\n",
            "7: Tax\n",
            "8: EPS\n",
            "9: Sundry Debtors/Current Assets\n",
            "10: Cash & Bank Balances/Total Liabilities\n",
            "11: Inventory/Current Assets\n",
            "12: Debt/Liability\n",
            "13: Contingent Liabilities/Networth\n",
            "Enter your choice!6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### News\n",
        "\n",
        "We tend to extract all the latest top news about the company!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FOxiUTGn5Aox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading necessary dependencies\n",
        "!pip3 install pygooglenews\n",
        "!pip3 install GoogleNews\n",
        "!pip3 install newspaper3k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrrHaueloRwC",
        "outputId": "cd13f055-2e52-46b9-f4ff-c0216d913bd1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygooglenews in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: dateparser<0.8.0,>=0.7.6 in /usr/local/lib/python3.7/dist-packages (from pygooglenews) (0.7.6)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.7/dist-packages (from pygooglenews) (4.11.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pygooglenews) (2.27.1)\n",
            "Requirement already satisfied: feedparser<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pygooglenews) (5.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->pygooglenews) (2.3.2.post1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (1.5.1)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2019.12.20)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2022.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2022.5.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser<0.8.0,>=0.7.6->pygooglenews) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: GoogleNews in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (4.11.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (2.8.2)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (0.7.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4->GoogleNews) (2.3.2.post1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (2022.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (1.5.1)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->GoogleNews) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.7/dist-packages (0.2.8)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (5.2.1)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (1.1.0)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.27.1)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.3.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the useful libraries\n",
        "from pygooglenews import GoogleNews\n",
        "from newspaper import Article\n",
        "from newspaper import Config\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsOdCaH3o6Nc",
        "outputId": "6d7f944c-bf59-4379-d118-26c8e16f053f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the configuration to get access from most websites\n",
        "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
        "config = Config()\n",
        "config.browser_user_agent = user_agent"
      ],
      "metadata": {
        "id": "GqW-YXicm7ZK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the environment by initializations\n",
        "gn = GoogleNews()\n",
        "s = gn.search('Tata Steel', when = '5y')\n",
        "\n",
        "sno = []\n",
        "title = []\n",
        "published = []\n",
        "author = []\n",
        "links = []\n",
        "content = []\n",
        "summary = []"
      ],
      "metadata": {
        "id": "2yvz1yFPIjdE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting all the information for every news i.e. title, published data, url, content, etc.\n",
        "entries = s[\"entries\"]\n",
        "count = 0\n",
        "for entry in entries:\n",
        "  count = count + 1\n",
        "  sno.append(count)\n",
        "  title.append(entry[\"title\"])\n",
        "  published.append(entry[\"published\"])\n",
        "  links.append(entry[\"link\"])\n",
        "  url = entry[\"link\"]\n",
        "  article = Article(url, config=config)\n",
        "  try:\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    article.nlp()\n",
        "    content.append(article.text)\n",
        "    summary.append(article.summary)\n",
        "  except:\n",
        "    content.append(' ')\n",
        "    summary.append(' ')\n",
        "    continue"
      ],
      "metadata": {
        "id": "Wq-dLJRNIo23"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining our results as a csv file\n",
        "df = pd.DataFrame ({'S.No.': sno, \n",
        "                    'Title': title,\n",
        "                    'Published': published,\n",
        "                    'Content': content,\n",
        "                    'Summary': summary,\n",
        "                    'Links': links})\n",
        "\n",
        "df.to_csv('news.csv', index=False)"
      ],
      "metadata": {
        "id": "8K_XjKcYI37i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H9wcCh0RI8me"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}