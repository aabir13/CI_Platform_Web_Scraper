{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aabir13/CI_Platform_Web_Scraper/blob/main/Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Web Scraper**\n",
        "\n",
        "To scrape all the necessary content about Tata Steel from Money Control website!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CmRL8MziNOP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Peers\n",
        "Based on 13 criterion we extract the Top Peer competitors of Iron and Steel!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dPR_IFHu8tVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install html-table-parser-python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqHCC299BCRg",
        "outputId": "fd4dc1dd-3d0b-48e7-c2d5-f62fbbc3b95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting html-table-parser-python3\n",
            "  Downloading html_table_parser_python3-0.2.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: html-table-parser-python3\n",
            "Successfully installed html-table-parser-python3-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import urllib.request\n",
        "from html_table_parser.parser import HTMLTableParser\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "10D1hlKrNeF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To read the binary contents of the html body\n",
        "def url_get_contents(url):\n",
        "  req = urllib.request.Request(url=url)\n",
        "  f = urllib.request.urlopen(req)\n",
        "  return f.read()"
      ],
      "metadata": {
        "id": "nK4LXciwA1U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Net Sales as per the latest Profit & Loss Account available: df1\n",
        "def Net_Sales():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/netsales/bse/iron-steel.html').decode('utf-8')\n",
        "  # html parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into the dataframe\n",
        "  df1 = pd.DataFrame(p.tables[2])\n",
        "  df1 = df1.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df1 = df1.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  # Obtaining the csv file\n",
        "  df1.to_csv('Net_Sales_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "Uh2gjKtnB6D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Net Profit as per the latest Profit & Loss Account available: df2\n",
        "def Net_Profit():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/netprofit/bse/iron-steel.html').decode('utf-8')\n",
        "  # html parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into the dataframe\n",
        "  df2 = pd.DataFrame(p.tables[2])\n",
        "  df2 = df2.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df2 = df2.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  # Obtaining the csv file\n",
        "  df2.to_csv('Net_Profit_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "a1ah8tCwFsR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Market capitalisation: df3\n",
        "def Market_Capitalization():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/marketcap/bse/iron-steel.html').decode('utf-8')\n",
        "  # html parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into the dataframe\n",
        "  print('Iron & Steel')\n",
        "  print('Market capitalisation as per the latest Profit & Loss Account available')\n",
        "  df3 = pd.DataFrame(p.tables[1])\n",
        "  df3 = df3.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df3 = df3.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  # Obtaining the csv file\n",
        "  df3.to_csv('Market_Capitalisation_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "itfgDuhrnG6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total Assets as per the latest Balance Sheet available: df4\n",
        "def Total_Assets():\n",
        "  xhtml=url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/totassets/bse/iron-steel.html').decode('utf-8')\n",
        "  #HTML parser object\n",
        "  p=HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from the required table into a dataframe\n",
        "  df4 = pd.DataFrame(p.tables[2])\n",
        "  df4 = df4.replace({\"Add to Watchlist\": \"\"}, regex=True)\n",
        "  df4 = df4.replace({\"Add to Portfolio\": \"\"}, regex=True)\n",
        "  #Obtaining the csv file\n",
        "  df4.to_csv('Total_Assest_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "jtyjwD6dOT3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other Income as per the latest Profit & Loss Account available: df5\n",
        "def Other_Income():\n",
        "  xhtml=url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/othinc/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p=HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df5=pd.DataFrame(p.tables[2])\n",
        "  df5=df5.replace({\"Add to Watchlist\":\"\"}, regex=True)\n",
        "  df5=df5.replace({\"Add to Portfolio\":\"\"}, regex=True)\n",
        "  # Obtaining csv\n",
        "  df5.to_csv('Other_Income_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "ivv84i-7PzHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interest as per the latest Profit & Loss Account available: df6\n",
        "def Interest():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/interest/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df6=pd.DataFrame(p.tables[2])\n",
        "  df6=df6.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df6=df6.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv \n",
        "  df6.to_csv('Interest_Iron_and_Steel.csv') "
      ],
      "metadata": {
        "id": "Wn0TN1fBSN0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tax as per the latest Profit & Loss Account available: df7\n",
        "def Tax():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/tax/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df7=pd.DataFrame(p.tables[2])\n",
        "  df7=df7.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df7=df7.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df7.to_csv('Tax_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "a7ocCpkSTtV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trailing Twelve Months EPS: df8\n",
        "def Trailing_Twelve_Months_EPS():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/eps/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df8=pd.DataFrame(p.tables[2])\n",
        "  df8=df8.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df8=df8.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df8.to_csv('EPS_Iron_and_Steel.csv')"
      ],
      "metadata": {
        "id": "FECHy17iUaID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sundry Debtors/Current Assets figures as per the latest Balance Sheet available: df9\n",
        "def Sundry_Debtors():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/sdrs/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df9=pd.DataFrame(p.tables[2])\n",
        "  df9=df9.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df9=df9.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df9.to_csv('Sundry Debtors_Iron_and_Steel.csv') "
      ],
      "metadata": {
        "id": "5G-zdoyWU6Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cash & Bank Balances/Total Liabilities figures as per the latest Balance Sheet available: df10\n",
        "def Cash_and_Bank_Balances():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/cashbank/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df10=pd.DataFrame(p.tables[2])\n",
        "  df10=df10.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df10=df10.replace({\"Add to Portfolio\":\"\"}, regex = True)\n",
        "  # Obtaining csv\n",
        "  df10.to_csv('Cash_&_Bank_Balances_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "fIf_GjPNVgUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inventory/Current Assets figures as per the latest Balance Sheet available: df11\n",
        "def Current_Assets():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/inventory/bse/iron-steel.html').decode('utf-8')\n",
        "  #HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df11=pd.DataFrame(p.tables[2])\n",
        "  df11=df11.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df11=df11.replace({\"Add to Portfolio\":\"\"}, regex = True) \n",
        "  # Obtaining csv\n",
        "  df11.to_csv('Inventory_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "7TBIS6BpXaGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debt/Liability figures as per the latest Balance Sheet available: df12\n",
        "def Debt():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/debt/bse/iron-steel.html').decode('utf-8')\n",
        "  # HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df12=pd.DataFrame(p.tables[2])\n",
        "  df12=df12.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df12=df12.replace({\"Add to Portfolio\":\"\"}, regex = True) \n",
        "  # Obtaining csv\n",
        "  df12.to_csv('Debt_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "uSCDR3obYAtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contingent Liabilities/Networth figures as per the latest Balance Sheet available: df13\n",
        "def Contingent_Liabilities():\n",
        "  xhtml = url_get_contents('https://www.moneycontrol.com/stocks/marketinfo/contliab/bse/iron-steel.html').decode('utf-8')\n",
        "  #HTML parser object\n",
        "  p = HTMLTableParser()\n",
        "  p.feed(xhtml)\n",
        "  # Obtaining the data from required table into the dataframe\n",
        "  df13=pd.DataFrame(p.tables[2])\n",
        "  df13=df13.replace({\"Add to Watchlist\":\"\"}, regex = True)\n",
        "  df13=df13.replace({\"Add to Portfolio\":\"\"}, regex = True) \n",
        "  # Obtaining csv\n",
        "  df13.to_csv('Contingent_Liabilities_Iron_and_Steel.csv')    "
      ],
      "metadata": {
        "id": "41unwr8MYkUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Driver Function\n",
        "print('Category: IRON AND STEEL')\n",
        "print('Select the criteria in which you want to categorize the companies:')\n",
        "print('1: Net Sales')\n",
        "print('2: Net Profit')\n",
        "print('3: Market Capitalization')\n",
        "print('4: Total Assets')\n",
        "print('5: Other Income')\n",
        "print('6: Interest')\n",
        "print('7: Tax')\n",
        "print('8: EPS')\n",
        "print('9: Sundry Debtors/Current Assets')\n",
        "print('10: Cash & Bank Balances/Total Liabilities')\n",
        "print('11: Inventory/Current Assets')\n",
        "print('12: Debt/Liability')\n",
        "print('13: Contingent Liabilities/Networth')\n",
        "n = int(input('Enter your choice!'))\n",
        "if n==1:\n",
        "  Net_Sales()\n",
        "elif n==2:\n",
        "  Net_Profit()\n",
        "elif n==3:\n",
        "  Market_Capitalization()\n",
        "elif n==4:\n",
        "  Total_Assets()\n",
        "elif n==5:\n",
        "  Other_Income()\n",
        "elif n==6:\n",
        "  Interest()\n",
        "elif n==7:\n",
        "  Tax()\n",
        "elif n==8:\n",
        "  Trailing_Twelve_Months_EPS()\n",
        "elif n==9:\n",
        "  Sundry_Debtors()\n",
        "elif n==10:\n",
        "  Cash_and_Bank_Balances()\n",
        "elif n==11:\n",
        "  Current_Assets()\n",
        "elif n==12:\n",
        "  Debt()\n",
        "elif n==13:\n",
        "  Contingent_Liabilities()\n",
        "else:\n",
        "  print('Sorry! Wrong choice of category!')"
      ],
      "metadata": {
        "id": "a77squY-YwH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b1de57-ca8b-4a38-dee4-923b431e8232"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category: IRON AND STEEL\n",
            "Select the criteria in which you want to categorize the companies:\n",
            "1: Net Sales\n",
            "2: Net Profit\n",
            "3: Market Capitalization\n",
            "4: Total Assets\n",
            "5: Other Income\n",
            "6: Interest\n",
            "7: Tax\n",
            "8: EPS\n",
            "9: Sundry Debtors/Current Assets\n",
            "10: Cash & Bank Balances/Total Liabilities\n",
            "11: Inventory/Current Assets\n",
            "12: Debt/Liability\n",
            "13: Contingent Liabilities/Networth\n",
            "Enter your choice!2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### News\n",
        "\n",
        "We tend to extract all the latest top news about the company!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FOxiUTGn5Aox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Approach 1"
      ],
      "metadata": {
        "id": "8DSktFJXNKnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading necessary dependencies\n",
        "!pip3 install pygooglenews\n",
        "!pip3 install GoogleNews\n",
        "!pip3 install newspaper3k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrrHaueloRwC",
        "outputId": "7230193c-fb62-426c-8840-c5b84e1750ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygooglenews\n",
            "  Downloading pygooglenews-0.1.2-py3-none-any.whl (10 kB)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.9.1\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting dateparser<0.8.0,>=0.7.6\n",
            "  Downloading dateparser-0.7.6-py2.py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 38.2 MB/s \n",
            "\u001b[?25hCollecting feedparser<6.0.0,>=5.2.1\n",
            "  Downloading feedparser-5.2.1.zip (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.3 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->pygooglenews) (2.3.2.post1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (1.5.1)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser<0.8.0,>=0.7.6->pygooglenews) (2022.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->pygooglenews) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser<0.8.0,>=0.7.6->pygooglenews) (1.15.0)\n",
            "Building wheels for collected packages: feedparser\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-py3-none-any.whl size=44952 sha256=85660f661612fec4ed77e50d959d0e04e97d8608cd3e96fe6d0a0214a1ce7485\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/bf/46/b4a597d435d3aee6c2fa583824897336d65abf13ebe3405b70\n",
            "Successfully built feedparser\n",
            "Installing collected packages: requests, feedparser, dateparser, beautifulsoup4, pygooglenews\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed beautifulsoup4-4.11.1 dateparser-0.7.6 feedparser-5.2.1 pygooglenews-0.1.2 requests-2.27.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GoogleNews\n",
            "  Downloading GoogleNews-1.6.2-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (4.11.1)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (0.7.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from GoogleNews) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4->GoogleNews) (2.3.2.post1)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (2019.12.20)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser->GoogleNews) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->GoogleNews) (1.15.0)\n",
            "Installing collected packages: GoogleNews\n",
            "Successfully installed GoogleNews-1.6.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting tldextract>=2.0.1\n",
            "  Downloading tldextract-3.3.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (5.2.1)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "Collecting jieba3k>=0.35.1\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.11.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2022.5.18.1)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.7.0)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13553 sha256=70dd4441cabec35ef9a013c0a7f880b81376add5b97abc873bfc3b25e526227e\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3357 sha256=59cdfd0c27e9ab3bff31ec139bedbcd90f7178ab0c4c068acbfd67b137e6a364\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=3495a57abafa0c7c1f2261786dd175e870c05cae74f531c5c9eced5527e023b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k\n",
            "Installing collected packages: requests-file, tldextract, tinysegmenter, jieba3k, feedfinder2, cssselect, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the useful libraries\n",
        "from pygooglenews import GoogleNews\n",
        "from newspaper import Article\n",
        "from newspaper import Config\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsOdCaH3o6Nc",
        "outputId": "47d1ee54-c646-453b-88e1-abcdf0500c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the configuration to get access from most websites\n",
        "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
        "config = Config()\n",
        "config.browser_user_agent = user_agent"
      ],
      "metadata": {
        "id": "GqW-YXicm7ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the environment by initializations\n",
        "gn = GoogleNews()\n",
        "s = gn.search('Tata Steel', when = '5y')\n",
        "\n",
        "sno = []\n",
        "title = []\n",
        "published = []\n",
        "links = []\n",
        "content = []\n",
        "summary = []"
      ],
      "metadata": {
        "id": "2yvz1yFPIjdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting all the information for every news i.e. title, published data, url, content, etc.\n",
        "entries = s[\"entries\"]\n",
        "count = 0\n",
        "for entry in entries:\n",
        "  count = count + 1\n",
        "  sno.append(count)\n",
        "  title.append(entry[\"title\"])\n",
        "  published.append(entry[\"published\"])\n",
        "  links.append(entry[\"link\"])\n",
        "  url = entry[\"link\"]\n",
        "  article = Article(url, config=config)\n",
        "  try:\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    article.nlp()\n",
        "    content.append(article.text)\n",
        "    summary.append(article.summary)\n",
        "  except:\n",
        "    content.append(' ')\n",
        "    summary.append(' ')\n",
        "    continue"
      ],
      "metadata": {
        "id": "Wq-dLJRNIo23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining our results as a csv file\n",
        "df = pd.DataFrame ({'S.No.': sno, \n",
        "                    'Title': title,\n",
        "                    'Published': published,\n",
        "                    'Content': content,\n",
        "                    'Summary': summary,\n",
        "                    'Links': links})\n",
        "\n",
        "df.to_csv('news.csv', index=False)"
      ],
      "metadata": {
        "id": "8K_XjKcYI37i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Approach 2"
      ],
      "metadata": {
        "id": "IZN-B-OkNNvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependencies\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from GoogleNews import GoogleNews\n",
        "from newspaper import Article\n",
        "from newspaper import Config\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "nltk.download('vader_lexicon') #required for Sentiment Analysis"
      ],
      "metadata": {
        "id": "Mdpdonkwb_Yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e5f4ad-5cdb-4978-c0f1-4955ac076095"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting date for extracting news\n",
        "now = dt.date.today()\n",
        "now = now.strftime('%m-%d-%Y')\n",
        "yesterday = dt.date.today() - dt.timedelta(days=1)\n",
        "yesterday = yesterday.strftime('%m-%d-%Y')\n",
        "\n",
        "# Configuring the model to obtain data access from maximum websites\n",
        "nltk.download('punkt')\n",
        "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
        "config = Config()\n",
        "config.browser_user_agent = user_agent\n",
        "config.request_timeout = 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuu-HGofpVuS",
        "outputId": "086e307a-5398-46e3-963d-d2115f854c09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "company_name = input(\"Please enter the name of the Company to obtain the results: \")\n",
        "\n",
        "print(f'Searching for and analyzing {company_name}, Please be patient, it might take a while...')\n",
        "\n",
        "googlenews = GoogleNews(start=yesterday, end=now)\n",
        "googlenews.search(company_name)\n",
        "result = googlenews.result()\n",
        "\n",
        "df = pd.DataFrame(result)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u3Dl0JCqYGC",
        "outputId": "1aa9a76c-a36c-4987-d9aa-05f0ba8b3617"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the name of the Company to obtain the results: Tata Steel\n",
            "Searching for and analyzing Tata Steel, Please be patient, it might take a while...\n",
            "                                               title  \\\n",
            "0  Tata Steel, JSW, SAIL and JSPL will lose half ...   \n",
            "1  BPCL, Grasim Industries among 223 stocks to hi...   \n",
            "2  Sensex rises 503 points, Nifty ends at 16,170;...   \n",
            "3  Tata Steel Jamshedpur plant earns recognition ...   \n",
            "4  DURASHINE by Tata BlueScope Steel launches All...   \n",
            "5  Steel Pipes and Tubes Market Exhibits Higher G...   \n",
            "6  Bharti Airtel, Nykaa, Hindalco, BPCL, Tata Pow...   \n",
            "7  The Top 5: Steel Companies in India & Their Co...   \n",
            "8  India shares higher at close of trade; Nifty 5...   \n",
            "9  Share Market Live: Sensex rises 450 points, Ni...   \n",
            "\n",
            "                       media         date                   datetime  \\\n",
            "0     Business Insider India    1 day ago 2022-05-26 13:19:31.764881   \n",
            "1      The Financial Express    1 day ago 2022-05-26 13:19:31.788184   \n",
            "2                News on Air    1 day ago 2022-05-26 13:19:31.806784   \n",
            "3            The Avenue Mail   1 hour ago 2022-05-27 12:19:31.825845   \n",
            "4                   ANI News  4 hours ago 2022-05-27 09:19:31.844502   \n",
            "5                 openPR.com  3 hours ago 2022-05-27 10:19:31.863027   \n",
            "6      The Financial Express  0 hours ago 2022-05-27 13:19:31.866124   \n",
            "7  Saur Energy International  2 hours ago 2022-05-27 11:19:31.886158   \n",
            "8              Investing.com    1 day ago 2022-05-26 13:19:31.906649   \n",
            "9             Business Today  0 hours ago 2022-05-27 13:19:31.908571   \n",
            "\n",
            "                                                desc  \\\n",
            "0  Tata Steel, JSW, SAIL and JSPL will lose half ...   \n",
            "1  In the Nifty pack, JSW Steel, Tata Steel, HDFC...   \n",
            "2  Tata Steel was the top gainer among blue-chip ...   \n",
            "3  Jamshedpur, May 27: Tata Steel's Jamshedpur St...   \n",
            "4  DURASHINE by Tata BlueScope Steel launches All...   \n",
            "5  Nippon Steel Corp. • NSSMC • Rama Steel Tubes ...   \n",
            "6  Bharti Airtel, Nykaa, Hindalco, BPCL, Tata Pow...   \n",
            "7  Tata Steel has a mission to bring down the car...   \n",
            "8  The top performers on the BSE Sensex 30 were T...   \n",
            "9  Tata Steel SBI, HDFC Bank and Axis Bank were a...   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://www.businessinsider.in/business/corpor...   \n",
            "1  https://www.financialexpress.com/market/bpcl-g...   \n",
            "2  https://newsonair.com/2022/05/26/sensex-rises-...   \n",
            "3  https://avenuemail.in/tata-steel-jamshedpur-pl...   \n",
            "4  https://www.aninews.in/news/business/business/...   \n",
            "5  https://www.openpr.com/news/2638739/steel-pipe...   \n",
            "6  https://www.financialexpress.com/market/stocks...   \n",
            "7  https://www.saurenergy.com/solar-energy-blog/t...   \n",
            "8  https://in.investing.com/news/india-shares-hig...   \n",
            "9  https://www.businesstoday.in/markets/stocks/st...   \n",
            "\n",
            "                                                 img  \n",
            "0  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "1  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "2  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "3  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "4  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "5  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "6  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "7  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "8  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n",
            "9  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  list = []\n",
        "  for i in df.index:\n",
        "    dict = {}\n",
        "    article = Article(df['link'][i], config=config)\n",
        "    try:\n",
        "      article.download()\n",
        "      article.parse()\n",
        "      article.nlp()\n",
        "    except:\n",
        "      pass\n",
        "    dict['Date'] = df['date'][i]\n",
        "    dict['Media'] = df['media'][i]\n",
        "    dict['Title'] = article.title\n",
        "    dict['Article'] = article.text\n",
        "    dict['Summary'] = article.summary\n",
        "    dict['Key_words'] = article.keywords\n",
        "    list.append(dict)\n",
        "  check_empty = not any(list)\n",
        "  if check_empty == False:\n",
        "    news_df = pd.DataFrame(list)\n",
        "    print(news_df)\n",
        "  \n",
        "except Exception as e:\n",
        "  print(\"Exception occured: \"+str(e))\n",
        "  print(\"Looks like, there is some error in retrieving the data, Please try again or try with a different ticker.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vM3lZJMq-vu",
        "outputId": "09de326a-db49-4e17-bf3c-63df3f9a6eae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date                      Media  \\\n",
            "0    1 day ago     Business Insider India   \n",
            "1    1 day ago      The Financial Express   \n",
            "2    1 day ago                News on Air   \n",
            "3   1 hour ago            The Avenue Mail   \n",
            "4  4 hours ago                   ANI News   \n",
            "5  3 hours ago                 openPR.com   \n",
            "6  0 hours ago      The Financial Express   \n",
            "7  2 hours ago  Saur Energy International   \n",
            "8    1 day ago              Investing.com   \n",
            "9  0 hours ago             Business Today   \n",
            "\n",
            "                                               Title  \\\n",
            "0  Tata Steel, JSW, SAIL and JSPL will lose half ...   \n",
            "1  BPCL, Grasim Industries among 223 stocks to hi...   \n",
            "2  Sensex rises 503 points, Nifty ends at 16,170;...   \n",
            "3  Tata Steel Jamshedpur plant earns recognition ...   \n",
            "4  DURASHINE by Tata BlueScope Steel launches All...   \n",
            "5                                                      \n",
            "6  Bharti Airtel, Nykaa, Hindalco, BPCL, Tata Pow...   \n",
            "7  The Top 5: Steel Companies in India & Their Co...   \n",
            "8  India shares higher at close of trade; Nifty 5...   \n",
            "9  Share Market Update: Sensex rises 632 points, ...   \n",
            "\n",
            "                                             Article  \\\n",
            "0  Shares of India’s largest steel companies tumb...   \n",
            "1  Indian benchmark indices reversed early mornin...   \n",
            "2  Indian equity indices closed higher on Thursda...   \n",
            "3  Jamshedpur, May 27: Tata Steel’s Jamshedpur St...   \n",
            "4  Pune (Maharashtra) [India], May 27 (ANI/NewsVo...   \n",
            "5                                                      \n",
            "6  Indian equity markets are likely to open gap-u...   \n",
            "7  Highlights : Indian Steel Association: Steel c...   \n",
            "8  Investing.com – India equities were higher at ...   \n",
            "9  The Indian market opened higher today amid pos...   \n",
            "\n",
            "                                             Summary  \\\n",
            "0  Shares of India’s largest steel companies tumb...   \n",
            "1  The S&P BSE Sensex was down 200 points or 0.38...   \n",
            "2  China’s Shanghai Composite index surged by 0.5...   \n",
            "3  Jamshedpur, May 27: Tata Steel’s Jamshedpur St...   \n",
            "4  DURASHINE® roofing solutions not only promise ...   \n",
            "5                                                      \n",
            "6  “Market witnessed a relief rally after 3 days ...   \n",
            "7  Thus, with a vision and in a response to the n...   \n",
            "8  Investing.com – India equities were higher at ...   \n",
            "9  Sensex rose 457 points to 54,709 and Nifty gai...   \n",
            "\n",
            "                                           Key_words  \n",
            "0  [impact, steel, half, jsw, export, exports, lo...  \n",
            "1  [steel, highs, bpcl, 52week, bank, sensex, sto...  \n",
            "2  [rose, index, steel, ends, 16170, cent, gained...  \n",
            "3  [recognition, global, forum, steel, network, e...  \n",
            "4  [launches, bluescope, steel, superior, solutio...  \n",
            "5                                                 []  \n",
            "6  [hindalco, steel, power, renewable, jsw, polic...  \n",
            "7  [reduce, steel, tonnes, co2, firm, carbon, ind...  \n",
            "8  [rose, unchanged, bo, steel, higher, ns, nifty...  \n",
            "9  [rose, 632, ends, higher, rs, bank, market, ni...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis\n",
        "def percentage(part,whole):\n",
        "  return 100*float(part)/float(whole)\n",
        "\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "\n",
        "news_list = []\n",
        "neutral_list = []\n",
        "negative_list = []\n",
        "positive_list = []"
      ],
      "metadata": {
        "id": "KzihyW3VshSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}